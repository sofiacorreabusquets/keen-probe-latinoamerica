{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a47708aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4bca24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id_interno', 'entidad', 'pais', 'score', 'vector_index', 'total_preguntas', 'data_hash_origen'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load score_by_entity and find all vector_indices\n",
    "with open(\"score_by_entity.json\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36458a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12014\n"
     ]
    }
   ],
   "source": [
    "ent_indices = {d[\"entidad\"]: d[\"vector_index\"] for d in data}\n",
    "print(len(ent_indices))\n",
    "target_keys = list(ent_indices.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daa9cb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors to be kept (matching keys): 12014\n",
      "----------------------------------------\n",
      "✅ Success! Filtered data saved to: 'filtered_vectors.npz'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- 1. Define File Paths and Target Keys ---\n",
    "# NOTE: input npz file is gitignored due to size\n",
    "INPUT_NPZ_PATH = 'state_b8d56cb4aa70_hs.npz' \n",
    "OUTPUT_NPZ_PATH = 'filtered_vectors.npz'\n",
    "\n",
    "\n",
    "# --- 2. Load the Original Data ---\n",
    "try:\n",
    "    with np.load(INPUT_NPZ_PATH) as data:\n",
    "        # Load the critical arrays\n",
    "        norm_reps = data['representations_normalized']\n",
    "        row_indices = data['row_indices']        \n",
    "        \n",
    "        # --- 3. Find the positions (indices) to filter ---\n",
    "        \n",
    "        # Convert the target_keys list to a NumPy array for efficient comparison\n",
    "        target_keys_np = np.array(target_keys) \n",
    "        \n",
    "        # Use np.isin to create a boolean mask: \n",
    "        # True where row_indices value is present in target_keys_np\n",
    "        filter_mask = np.isin(row_indices, target_keys_np)\n",
    "        \n",
    "        # Count how many vectors we are keeping\n",
    "        num_kept = np.sum(filter_mask)\n",
    "        print(f\"Number of vectors to be kept (matching keys): {num_kept}\")\n",
    "        \n",
    "        # --- 4. Filter the Arrays using the Mask ---\n",
    "        \n",
    "        # Apply the mask to all relevant arrays. The mask must be 1-dimensional \n",
    "        # and match the first dimension of the arrays being filtered.\n",
    "        filtered_norm_reps = norm_reps[filter_mask]\n",
    "        filtered_row_indices = row_indices[filter_mask]\n",
    "                        \n",
    "        # --- 5. Save the Filtered Data to a New .npz File ---\n",
    "        np.savez(\n",
    "            OUTPUT_NPZ_PATH,\n",
    "            representations_normalized=filtered_norm_reps,\n",
    "            row_indices=filtered_row_indices\n",
    "        )\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "        print(f\"✅ Success! Filtered data saved to: '{OUTPUT_NPZ_PATH}'\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{INPUT_NPZ_PATH}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44190653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved filtered_vectors1.npz: representations_normalized shape (6007, 3072), row_indices shape (6007,)\n",
      "Saved filtered_vectors2.npz: representations_normalized shape (6007, 3072), row_indices shape (6007,)\n"
     ]
    }
   ],
   "source": [
    "# Split the filtered data into two roughly equal parts and save to two .npz files.\n",
    "# Uses existing variables: filtered_norm_reps, filtered_row_indices, num_kept, np\n",
    "\n",
    "n = int(num_kept)  # ensure native int\n",
    "split = (n + 1) // 2  # put the extra item (if odd) into the first file\n",
    "\n",
    "# Slices\n",
    "rep1, idx1 = filtered_norm_reps[:split], filtered_row_indices[:split]\n",
    "rep2, idx2 = filtered_norm_reps[split:], filtered_row_indices[split:]\n",
    "\n",
    "# Filenames\n",
    "OUT1 = \"filtered_vectors1.npz\"\n",
    "OUT2 = \"filtered_vectors2.npz\"\n",
    "\n",
    "# Save (use compressed format to save disk space)\n",
    "np.savez_compressed(OUT1, representations_normalized=rep1, row_indices=idx1)\n",
    "np.savez_compressed(OUT2, representations_normalized=rep2, row_indices=idx2)\n",
    "\n",
    "# Quick verification printout\n",
    "print(f\"Saved {OUT1}: representations_normalized shape {rep1.shape}, row_indices shape {idx1.shape}\")\n",
    "print(f\"Saved {OUT2}: representations_normalized shape {rep2.shape}, row_indices shape {idx2.shape}\")\n",
    "assert rep1.shape[0] + rep2.shape[0] == filtered_norm_reps.shape[0]\n",
    "assert idx1.shape[0] + idx2.shape[0] == filtered_row_indices.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
