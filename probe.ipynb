{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "702bb01a",
   "metadata": {},
   "source": [
    "# Copied code from keen-source\n",
    "\n",
    "Find a cleaner fix later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0438efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "import torch\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "import random\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Deterministic Run\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "torch.set_num_threads(1)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "\n",
    "optimizers = {\n",
    "    \"adam\": optim.AdamW,\n",
    "    \"sgd\": optim.SGD\n",
    "}\n",
    "\n",
    "\n",
    "class MLPRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, optimizer, learning_rate, max_iter, T_max=None):\n",
    "        super(MLPRegressor, self).__init__()\n",
    "        self.max_iter = max_iter\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.last_activation = torch.sigmoid\n",
    "        self.layers =  nn.ModuleList(\n",
    "            [nn.Linear(input_size, 1, bias=False)]\n",
    "        )\n",
    "        self.best_weights = []\n",
    "        self.init_weights = []\n",
    "        self._initialize_weights()\n",
    "        self.optimizer = optimizers[optimizer](self.parameters(), lr=learning_rate)\n",
    "        self.best_train_loss, self.best_test_pearson_corr = 1, -1\n",
    "        self.initial_train, self.initial_test, self.final_train, self.final_test = None, None, None, None \n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for layer in self.layers:\n",
    "            torch.nn.init.kaiming_uniform_(layer.weight, nonlinearity=\"relu\")\n",
    "            self.init_weights.append(layer.weight)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            self.best_weights.append(layer.weight)\n",
    "\n",
    "    def set_to_best_weights(self):\n",
    "        for i, weight in enumerate(self.best_weights):\n",
    "            self.layers[i].weight = weight\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.layers[0](x)\n",
    "        return self.last_activation(x) \n",
    "\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            return self.forward(x)\n",
    "    \n",
    "    def validate(self, X_test, y_test):\n",
    "            preds = self.predict(X_test)\n",
    "            test_loss = self.criterion(preds, y_test).item()\n",
    "\n",
    "            result_df = pd.DataFrame(\n",
    "                {\n",
    "                    \"preds\": preds.squeeze(dim=-1).detach().cpu().numpy(), \n",
    "                    \"target\": y_test.squeeze(dim=-1).detach().cpu().numpy()\n",
    "                }\n",
    "            )\n",
    "            test_pearson_corr, test_pearson_p_value = pearsonr(result_df[\"preds\"], result_df[\"target\"])\n",
    "            return result_df, test_loss, test_pearson_corr, test_pearson_p_value\n",
    "\n",
    "    def fit(self, X_train, y_train, X_test, y_test):     \n",
    "        X_test = torch.tensor(X_test.tolist(), dtype=torch.float32).cuda()  \n",
    "        y_test = torch.tensor(y_test.tolist(), dtype=torch.float32).unsqueeze(dim=1).cuda()\n",
    "        for epoch in range(self.max_iter):\n",
    "            epoch_train_loss = 0.0\n",
    "            n_examples = 0\n",
    "            for batch in X_train:\n",
    "                # Train\n",
    "                self.optimizer.zero_grad()\n",
    "                preds = self.forward(batch[0].to(torch.float32).cuda())\n",
    "                train_loss = self.criterion(preds, batch[1].to(torch.float32).unsqueeze(dim=1).cuda())\n",
    "                train_loss.backward()\n",
    "                self.optimizer.step()\n",
    "                epoch_train_loss += train_loss.item()\n",
    "                n_examples += batch[0].shape[0]\n",
    "\n",
    "            if self.scheduler is not None:\n",
    "                self.scheduler.step()\n",
    "            \n",
    "            # Test \n",
    "            epoch_train_loss = epoch_train_loss / y_train.shape[0]\n",
    "            result_df, test_loss, test_spearman_corr, test_pearson_corr, test_pearson_p_value = self.validate(X_test, y_test)\n",
    "            \n",
    "            if epoch == 0:\n",
    "                self.initial_test = result_df\n",
    "            if test_pearson_corr > self.best_test_pearson_corr:\n",
    "                self.best_test_pearson_corr = test_pearson_corr\n",
    "                self.best_weights = [copy.deepcopy(l.weight)for l in self.layers]\n",
    "                self.final_test = result_df\n",
    "\n",
    "            wandb.log({\"test_loss\": test_loss, \"train_loss\": epoch_train_loss, \"test_spearman_corr\": test_spearman_corr, \"test_pearson_corr\": test_pearson_corr})     \n",
    "        wandb.finish() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bac7c53",
   "metadata": {},
   "source": [
    "# Load vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a63e14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "INPUT_NPZ_PATH = 'data/filtered_vectors.npz' \n",
    "\n",
    "try:\n",
    "    with np.load(INPUT_NPZ_PATH) as data:\n",
    "        norm_reps = data['representations_normalized']\n",
    "        row_indices = data['row_indices']\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{INPUT_NPZ_PATH}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bf4e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data\n",
    "with open('data/score_by_entity.json', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Create a dictionary mapping vector_index to score for O(1) lookup\n",
    "score_dict = {item['vector_index']: item['score'] for item in data}\n",
    "\n",
    "# Create scores list in the order determined by row_indices\n",
    "scores = np.array([score_dict[idx] for idx in row_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14377c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = norm_reps, scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
